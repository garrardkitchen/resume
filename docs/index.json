[{"categories":null,"contents":"These are some of the areas where I have dedicated my efforts when it comes to security:\n All vital and IPR associated systems are protected via MFA Grandular IAM permissions configured for AWS services, users and roles I always adhere to the Least Privilege Principle Web Application Firewall (OWASP) Web application XSS, SQL Injection, encoding, securing cookies, role \u0026amp; claims based authz I always encrypt data at rest and also when in transit I always encrypt systems credentials (including 3rd party\u0026rsquo;s) and always include extra layer of encryption All passwords are hashed To isolated blast radius of environments by separating dev/test \u0026amp; prod into different accounts. I restricted account user access in production When I need to share a password, I do it via keybase and I never accompanied it with username or other identifiable key. I use a password manager \u0026amp; where appropriate share credentials via this route (avoids colleague writing down and exposing during demo) I never show passwords via a communication platform (slack, skype, \u0026hellip;) If I use wifi, I use vyprvpn I educate my colleagues on the above actions \u0026amp; preventitive measures  ","permalink":"http://www.garrardkitchen.com/projects/creations/security/","tags":["security","tls","at rest","in transit","waf","hashed","password manager","wifi","owasp","iam","mfa"],"title":"Security"},{"categories":null,"contents":" Assessed whether or not to update existing non-maintained Jekyll site to promote myself Researched other options (e.g. Hugo) Experimented with Hugo and different templaes (focus on resume style) Expedited my learning curve Completed resume rewrite in 3 days Configured GitHub pages and custom domain Configured Google Analytics  ","permalink":"http://www.garrardkitchen.com/projects/creations/resume/","tags":["hugo","template configuration","google analytics","short deadline"],"title":"Resume"},{"categories":null,"contents":" Used mainly static content and ported new copy/layout to SAM Serverless Application C# .NET Core Razor Pages solution. Originally WP was in place, so removing MySQL reduced the cost. I created a CI/CD Pipeline using BitBucket. It is now hosted via API Gateway \u0026amp; Lambda and not via an Azure Website.  ","permalink":"http://www.garrardkitchen.com/projects/creations/corporate-website/","tags":["serverless","api gateway","serverless application model","ci/cd"],"title":"Corporate Website"},{"categories":null,"contents":" I have implemented several solutions around this space using serverless technology and purpose built services [Glue, Athena, Data Pipeline and DMS]. Tools that I have used to help me develop a solution are Jupyter Labs and Pandas \u0026amp; NumPy.  ","permalink":"http://www.garrardkitchen.com/projects/creations/etl/","tags":["etl","glue","s3","pandas","python","numpy","athena","data pipelines"],"title":"ETL"},{"categories":null,"contents":"  I have had the honour and experience of hiring several talented individuals.\nI have tried different approaches to assessing a team member. My secret is that I look for crucial character traits. Having tried different approaches to evaluating a prospects suitability, I have come to the conclusion that in most cases lengthy tests or situations that induce stress, are both unnecessary and unfair. I am of the opinion that if you are faced with that kind of situation then something/someone up stream has messed up and it’s more important to me to know how a person (a) handles that situation and (2) how they identify learning points.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/recruitment/","tags":["recruitment"],"title":"Recruitment"},{"categories":null,"contents":"  Coach has a long standing feature called IntelliSearch.\nIt is a feature that, at a specific time, for several set periods [daily, weekly, monthly, custom], it will submit queries to a Data Connector (conduit between our system and an external system) to match up randomly selected recordings for later evaluation. The random algorithm implemented is there to ensure fairness of recording selection so apples and apples are compared and not apples to oranges.\nThis has evolved over time to manage demand and reduced traffic bandwidth.\n  With CXcoach (cloud SaaS product), it was the prime candidate to be migrated to serverless. I architected the system and with the team we implemented the solution. The initial feature is designed for real-time processing so whenever there is a published event from the integrated system, the product obtains the latest information and at the appropriate time, it is loaded into ElasticSearch. The entire process is orchestrated using Step Functions, Lambdas, API Gateway, ElasticSearch \u0026amp; S3.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/intellisearch/","tags":["step functions","lambdas","api gateway","elasticsearch","s3","windows services","akka.net","nats","performance improvements"],"title":"IntelliSearch"},{"categories":null,"contents":" Serverless is ideal for so many use cases. Automation is a prime example of where serverless technology can fit so well. I have used Lambdas and supporting services to help automating both mundane and configuration tasks.\nSome examples of these are; setting log retention durations on log group creations, log subscription and adding API Gateway API keys to SSM Parameter Store.  ","permalink":"http://www.garrardkitchen.com/projects/creations/automation/","tags":["serverless","lambda","cloudwatch","aws ecs fargate"],"title":"Automation"},{"categories":null,"contents":"  Migrate Coach product away from a monolyth to being 100% serverless. Main web platform hosted via ECS Fargate and all features, RESTul APIs be Lambda backed API Gateways and Step Functions. Data repositories used are dynamoDB, ElasticSearch, Amazon Aurora (mySQL), Redis and S3.\n  Coach migrated from MSSQL to MySQL as costs were too high for Always-On capabilities. I was accepted onto Aurora MySQL Preview programme and contributed to this phase. The product had a key dependency that required a specific version of MySQL. As a result we are now using Amazon Aurora and plan to migrate over to Aurora Serverless when version 5.7 is supported.\n  To offer CXcoach to a greater audience, a web plug-in dependency had to be removed. This plug-in being Silverlight. Web service technology required for Silverlight had to be replaced with a more traditional RESTful API technology. This, with an reimagined UX, helped deliver a new experience.\n  I orchestrated the entire migration of a solution away from all Microsoft product dependencies. This drastic step was born out of being fed up with (a) overpriced software (e.g. MSSQL, especially in a highly available configuration) and customers having to spend huge amounts to use our products, (b) misdirection of technology (e.g. Silverlight, need I say more?!) and (3) general lack of emphathy with IT professionals who prescribe to doctrine of the MS stack. I decided some time ago that if I get the opportunity too, I will in all respects, pivot away from MS. The areas where it did not make sense to jump ship from is languages and development tools. I am a huge fan of C# \u0026amp; F# and I believe we [subjective I know] are all better of with having VS \u0026amp; VSCode in our lives.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/migrations/","tags":["serverless","ecs fargate","lambda","api gateway","step functions","silverlight","mssql","restful api","asp.net mvc","asp.net core","aws aurora","ux","aws dms","too expensive","microsoft"],"title":"Migrations"},{"categories":null,"contents":"  I have researched several big data solutions but found them either too costly, lead time too lengthy or too complicated.\nCoach needed something to present actionable data. Not knowing whether the idea matched reality, I proposed a phase 1 release that would lead to feature enhancements that would naturally lead to something that would help more. I architected an ETL and data analytics process that would generate separate JSON formatted data, persisted to S3 for a specific user after being processed by a Pandas dataframe. Implemented using CloudWatch trigger, S3, Redis \u0026amp; lambdas and Amazon Aurora (MySQL).\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/dashboard/","tags":["etl","lambda","pandas","jupyter labs","python","c#","asp.net core","s3","sqs","redis","cloudwatch trigger","amazon aurora"],"title":"Dashboard"},{"categories":null,"contents":" For me, CX (Customer Experience) is paramount. Even if there is an outage, the CX doesn’t have to suffer. In my current project, there are key AWS services, as well as the CXcoach product, that are required to be running for the application to function. I have architected both full systems and application features in such a way for them not to fail because of transient outages or worse and furthermore to provide instant feedback to users. This also includes not losing anything that has yet to be persisted. I architected and implemented a serverless solution to check at regular intervals the state of key application services and other endpoints (e.g. app health check). If an outage is experienced the ALB is switched to a Lambda backed LB where the user is provided with information up until the time the service(s) is back online. This is all hooked into Slack and OpsGenie.  ","permalink":"http://www.garrardkitchen.com/projects/creations/health/","tags":["cx","cloudwatch trigger","lambda","alb","python","lambda load balancer target","elasticsearch","http","amazon aurora","s3","redis"],"title":"Health of the SaaS product"},{"categories":null,"contents":" I have designed and implemented several billing mechanisms. Including designs/models orientated around licensing, another using AWS MMS (metering service) for the AWS QuickStart and more recently, one to capture product usage based on a specific frequency. The later architectured and delivered once again via serverless technology. Created web apps [some serverless] to provide visibility into usage Create application features to help mitigate restrictions on internet access Subscription models designed and developed for: per agent, per user, per period, per feature usage, per role  ","permalink":"http://www.garrardkitchen.com/projects/creations/billing/","tags":["windows services","aws metering service","s3","dynamodb","finance portal","lambda","asp.net framework 4.6",".net core"],"title":"Billing"},{"categories":null,"contents":"  An important part of a SaaS application, especially one that requires integrations to provide any measure of benefit, is onboarding.\nFor me, the advantages are simple.\n  Generally, CX needs to be smooth [quick and useful]. It is also important to know at what stage a trialer is at. This can then be aided by a digital campaign with support.\n  With most onboarding models requiring a starting point outside of our product, e.g. vendor, it is even more important that the trialer does not experience any pain during this process; even if they do experience a problem [e.g. outage].\nI set about designing an onboarding process and experience and presented it to the POs (product owners), emphasising the importance of how the initial experience of a new product to a user will determine their engagement, desirability for the product and their colleagues. The onboarding process is designed to be 100% serverless. I also designed enhancements to the product to provide user advice, based on role, as to where they were, during the stages of the product and advice on what they ought to do next, supported by an email campaign.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/onboarding/","tags":["ses","pinpoint","campaign","ux","ux"],"title":"Onboarding"},{"categories":null,"contents":"  Formally a front-end developer, I feel confortable and confident carrying out work in this space\n  The CXcoach cloud based product needed a ‘face lift’.\nI investigated the most frugal way to provide the product with a new look and feel, one that is aligned with industry expectations. I settled on an open source theme and provided my UX lead developer a branch of code that used this new theme for him to complete and fix any style and placement issues. For specific areas of the product (features), I provided the same person with a mock up (HTML and style) for him to incorporate into the React front-end.\n  I was a front-end developer previously and felt confident that what I had proposed could be implemented within an accepted deadline\n  After: Before: ","permalink":"http://www.garrardkitchen.com/projects/creations/retheme-product/","tags":["bootstrap","javascript","ux","ui","mock up","asp.net core","c#"],"title":"Retheme Product"},{"categories":null,"contents":"  I created a process for others, external to the company, to perform integrations. The concept is simple and still used today.\nIn summary, a conduit known as a Data Connector was developed to (a) be used by Coach via a RESTful API and (b) integrate with Vendor or other system(s) APIs or data sources. Metadata for users \u0026amp; recordings could then be exchanged via the Data Connector. Additional [configurable] data was also passed along this pipeline. Multiple authentication protocols and approaches were used to permit the flow of data. Data and required credentials were and are always encrypted. The SDK is supported by a sample data connector, API documentation and a test bed via the Azure Platform.\n  Create a developer website to contain all product materials for Coach product and contributed to materials produced\n  Developed integration tool to help integration engineers test their Data Connector\n  Links Sample Data Connector: https://github.com/qualtrak/recorder-qa\nIntegration Tool: http://dev.qualtrak.com/tool\n","permalink":"http://www.garrardkitchen.com/projects/creations/sdk/","tags":["integration tool","developer site","sdk","documentation","restful api","dependency injection","data connector"],"title":"SDK"},{"categories":null,"contents":" It is important to me to ensure throughout all my teams we all document, share and have joint responsibility in maintaining guidelines and best practices. It begins when research starts and continues through the projects lifecycle. Documents are maintained in order to provide guidance to both junior and senior team members. Always stress the importance of consistency and standards.  ","permalink":"http://www.garrardkitchen.com/projects/creations/best-practice/","tags":["best practice","joint responsibility"],"title":"Best Practice"},{"categories":null,"contents":"  The 3 pillars of observability (logging, metrics and tracing) presents new challenges for serverless solutions.\nHaving experienced this first hand, I set about looking for a solution that will enable rapid root cause analysis to ultimately greatly reduce or even better, mitigate [think runbooks] known undesirable scenarios.\n  I believe in positive Customer Experience (CX) and apply this philosophy across everything I do.\nI spent time with Datadog [a few months of meetings] discussing ways to help this serverless space to improve observability. I was accepted onto a few of their beta programmes. Coach’s cloud solution is 100% serverless which presents a unique challenge for tracing and logging. I liked what Datadog additionally had to offer. The company now uses their new APM for .NET Core and their Cloud Functions feature. Since then, I have, with the rest of the team, adopted a streamlined approach which is more workflow orientated. Using Epsagon for the lambda based solutions, Sentry.io for client-side and server-side error management. All observability solutions were researched and implemented by me. The company’s morning DSU, when necessary, use both Epsagon and Sentry.io to review priorities and where necessary, assign somebody to deal with an issue.\n  All work - greenfield, enhancements and defects - are managed through Jira. All project work and documentation is captured in Confluence. Confluence, like Jira, is very much an important productivity tool embedded into our working protocols.\n  Further applications I use in this area are: Datadog, Epsagon, Sentry, CloudWatch, OpsGenie.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/observability/","tags":["datadog","epsagon","sentry.io","opsgenie","cloudwatch","CX","serverless"],"title":"Observability"},{"categories":null,"contents":"  Created an SaaS version of our product on the AWS platform using serverless tech as an enabler to lowering the running costs and as such, make it cheaper for the vendor/partner to offer our product to their end-clients\n  I have been responsible for driving the integrations with major vendors\n  Made presentations to prospective partners [CEO and below] nd helped shape requirements of the integration\n  Platform required a new set of UX principles\nSome but not all included here: include client backoff retry pattern, ajax abort (propagate cancellation token or asynchronous requests), serverside messaging to loosely coupled components, using browser local storage to store data that is yet to be persisted, warm user of unsaved work before moving away from that page\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/cxcoach/","tags":["ecs fargate","lambda","step functions","api gateway","integrations","saas","ux"],"title":"CXcoach"},{"categories":null,"contents":" Created a web based product of our successful client/server product. Chose appropriate tech to fit the timeline. Worked with a Pakistani development outsourcing company and Recorder vendor that the product was integrating with at the time. Later developing the application to integrate with the Redbox Recorder, leading Redbox to purchase the code after an agreed sign off.  ","permalink":"http://www.garrardkitchen.com/projects/creations/coach/","tags":["asp.net mvc","silverlight","c#","jquery","angular","html","css","bootstrap","javascript","ajax","restful api","ria services","kendoui","telerik silverlight"],"title":"Coach"},{"categories":null,"contents":" For a particular integration, the necessary data for the integration was not discoverable. I architected a bespoke cloud based solution that used several Azure services. The web app was written with node.js, Azure mobile services, table storage, service bus and Azure Web App (plus staging).  ","permalink":"http://www.garrardkitchen.com/projects/creations/qtag/","tags":["node.js","azure mobile services","table storage","service bus","azure web services"],"title":"QTag"},{"categories":null,"contents":" The product, Coach, was in the first wave of SMEs to integrate with the Amazon Connect product. As part of a team, I met with and coordinated with both the AC team and the Marketplace Team. I developed the QuickStart that is hosted via AWS and produced an AMI that is being marketed in the AWS Marketplace. The Coach product was developed to work with Active Directory and I assisted in creating materials to help with all facets of the QuickStart. It was during this process that I was awarded my first AWS Certification - Developer Associate. I worked closely with several members of the AC and Marketplace teams. The QuickStart is a nested stack of CloudFormation [Configuration as Code] templates, incorporating both the AWS VPC and the Data Streaming QuickStarts.  Links QuickStart: https://aws.amazon.com/quickstart/connect/qualtrak-evaluate/\nGitHub: https://github.com/aws-quickstart/connect-integration-qualtrak-evaluate\nMarketplace: https://aws.amazon.com/marketplace/seller-profile?id=d12e19b4-04d3-4e1d-b8a7-0298f3862f33\nAWS What’s New: https://aws.amazon.com/about-aws/whats-new/2018/03/three-new-amazon-connect-integrations-offer-contact-center-solutions-from-qualtrak-solutions-voicebase-and-perficient/\nAWS Solution Space: https://aws.amazon.com/solutionspace/contact-center/qualtrak-evaluate-amazon-connect/\n","permalink":"http://www.garrardkitchen.com/projects/creations/aws-quickstart/","tags":["aws quick start","aws marketplace","cloudformation","aws ami","configuration as code","Amazon Connect"],"title":"AWS Quick Start for Amazon Connect"},{"categories":null,"contents":"  Investigated ways to reduce time to market, end-client license costs, hosting costs and development costs.\nThis research and later development efforts contributed to formulating and maintaining a best practice set of guidelines/principals covering all frameworks and languages employed to deliver a solution [product, automation and integrations].\n  Used both Serverless Framework and SAM. I use several IDEs, dependant on task/requirement, mainly VSCode, Rider, PyCharm and VS.\n  These are samples of use cases where I have employed Serverless technologies: Websites (ASP.NET Core Razor), major features (utilising full AWS stack), automation (set log retention via CLoudWatch Events, set Log subscription, Set API Gateway Key and store in SSM).\n  Contribute to Serverless Slack when I can.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/serverless/","tags":["serverless","lambda","api gateway","step functions","serverless framework","serverless application model","reduce cost","reduce time to market"],"title":"Serverless"},{"categories":null,"contents":"  The Coach product started as an on-prem application, installed behind the firewall on a single server.\nA partner made a request for the product [Coach] to be made highly available. Initially the product was hosted via an active/passive configuration. This was superseded by a load balanced active/active configuration through the application of Akka.NET throughout all components. This enabled an application cluster that could load balance the demands across all components. Based on specific feedback, I later re-architected the messaging driven solution and replaced Akka.NET with NATS.\n  I have previous experience of NATS with projects/research I have accomplished with Docker [Windows] and felt confident that this work could be completed in a limited timeframe. This previous research included both the use of C# and F#.\n  The HA solution for Coach is permanently on in a HA configuration on AWS (RDS, Redis, EC2 [windows], ALB, ACM, Route53).\n  Development work is conducted via AWS Workspaces [Windows] as and when required.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/ha/","tags":["nats.io","high availability","aws","single-server","multi-server","CI/CD"],"title":"Streamline deployment of HA app"},{"categories":null,"contents":" I created a culture that removes the responsibility of one person/team/department to manage infrastructure, and to deliver that freedom to the developer/team in order to minimize latency between feature conception and release and to react rapidly to any production issues  ","permalink":"http://www.garrardkitchen.com/projects/creations/devops/","tags":["devops","freedom","empowerment"],"title":"DevOps"},{"categories":null,"contents":"  CI has been a long term development responsibility.\nFormally, for our client/server product, I would install and host TeamCity on office servers. Currently for a specific version of Coach, it is now hosted on an Azure instance. The deployment package is delivered to S3 and at the appropriate time (major/minor/patch release) is added to a Confluence site for our customers to download.\nAll projects are now driven by CI/CD principals. This is for both on-premise and cloud solutions. Depending on the project and requirements, different tools have been used. R\u0026amp;D into use and application of these tools was my responsibility including introducing the original idea to the business and implementing across all projects. Tools used include Azure DevOps, BitBucket Pipelines, AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy, Octopus Deploy, Jenkins and TeamCity. All code is held in git repositories. These repositories include BitBucket (default), GitHub and CodeCommit. Each new feature, enhancement or defect is linked to a Jira issue.\n  I have architected several CI/CD solutions using the above listed technologies.\nKnowing that as a company we needed to evolve and advance, I had to start automating a lot more of our activities, I investigated what could be done. I presented my research and delivered my recommendations to the company and embarked on this as being an important tenet to how we automate this space. My original architecture started with Jenkins and Docker. I then promoted and embedded Azure DevOps and the company have used this for several years. More recently, AWS has been used for related services but now mainly for serverless solutions BitBucket Pipelines is used.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/cicd/","tags":["continuous integration","continuous deployment","continuous delivery","bitbucket pipelines","codebuild","codepipeLine","codedeploy","codecommit","github","azure devops"],"title":"Continuous Integration, Continuous Deployment \u0026 Continuous Delivery"},{"categories":null,"contents":"  Liaised with a vendor to create conduit [data connector] between our products and theirs. Worked with many vendors including Twilio (including Flex), Zendesk, Telax, DataVoice, Novo, Comways, Altitude, Dubber, Frequentis, Spitch, Amazon Connect, Redbox.\n  Worked with teams to scope requirements, define every stage up to sign off and team responsibilities. Each integration would start with a technical presentation delivered by me. This would encompass architecture, stages and responsibilities, establishing test environments and training requirements.\n  ","permalink":"http://www.garrardkitchen.com/projects/creations/integrations/","tags":["integration","twilio","zendesk","telax","datavoice","novo","comways","altitude","dubber","frequentis","spitch","amazon connect","redbox","world-wide","different cultures","different roles","project scope","training"],"title":"Integrations"}]